// src/hooks/useBaiduSpeechRecognition.js - å®Œæ•´ä¿®å¤ç‰ˆæœ¬
import { useState, useRef, useCallback, useEffect } from 'react';

const useBaiduSpeechRecognition = (options = {}) => {
  const [listening, setListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [finalTranscript, setFinalTranscript] = useState('');
  const [error, setError] = useState(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [status, setStatus] = useState('idle');
  const [audioLevel, setAudioLevel] = useState(0);
  const [permissionState, setPermissionState] = useState('prompt');
  const [audioMethod, setAudioMethod] = useState('none');

  // Refs
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const streamRef = useRef(null);
  const pcmDataRef = useRef([]);
  const isMountedRef = useRef(true);
  const abortControllerRef = useRef(null);
  const animationFrameRef = useRef(null);
  const processingActiveRef = useRef(false);
  const isStoppingRef = useRef(false);
  
  // éŸ³é¢‘å¤„ç†ä¸“ç”¨ refs
  const audioLevelRef = useRef(0);
  const lastUpdateTimeRef = useRef(0);
  const dataArrayRef = useRef(null);
  const bufferLengthRef = useRef(0);

  // æ·»åŠ å¯åŠ¨è¶…æ—¶æ£€æµ‹
  const startTimeoutRef = useRef(null);

  // æ·»åŠ è¯­éŸ³æ´»åŠ¨æ£€æµ‹
  const voiceActivityRef = useRef({
    hasSpeech: false,
    speechStartTime: 0,
    totalSamples: 0,
    silentSamples: 0,
    speechThreshold: 0.015,
    minSpeechDuration: 800
  });

  // ArrayBuffer è½¬ base64 å‡½æ•°
  const arrayBufferToBase64 = (buffer) => {
    let binary = '';
    const bytes = new Uint8Array(buffer);
    const len = bytes.byteLength;
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  };

  // ç”Ÿæˆå”¯ä¸€ç”¨æˆ·IDï¼ˆç±»ä¼¼å®˜æ–¹ç¤ºä¾‹ï¼‰
  const generateCuid = () => {
    return 'web_speech_' + Math.random().toString(36).substr(2, 9) + '_' + Date.now();
  };

  // è·å–ç™¾åº¦tokenï¼ˆé€šè¿‡åç«¯APIï¼‰
  const getBaiduToken = async () => {
    try {
      const response = await fetch('/api/baidu-token');
      const data = await response.json();
      if (data.token) {
        return data.token;
      } else {
        throw new Error('è·å–ç™¾åº¦tokenå¤±è´¥');
      }
    } catch (error) {
      console.error('è·å–ç™¾åº¦tokenå¤±è´¥:', error);
      throw new Error('è¯­éŸ³æœåŠ¡æš‚æ—¶ä¸å¯ç”¨');
    }
  };

  // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
  const checkBrowserSupport = useCallback(() => {
    const hasGetUserMedia = !!(navigator.mediaDevices?.getUserMedia);
    const hasAudioContext = !!(window.AudioContext || window.webkitAudioContext);
    return hasGetUserMedia && hasAudioContext;
  }, []);

  // èµ„æºæ¸…ç† - å¢å¼ºç‰ˆæœ¬
  const cleanupAudioResources = useCallback(async () => {
    if (!isMountedRef.current) return;

    console.log('ğŸ§¹ æ¸…ç†éŸ³é¢‘èµ„æº...');

    try {
      processingActiveRef.current = false;
      isStoppingRef.current = false;

      // æ¸…é™¤å¯åŠ¨è¶…æ—¶
      if (startTimeoutRef.current) {
        clearTimeout(startTimeoutRef.current);
        startTimeoutRef.current = null;
      }

      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      if (abortControllerRef.current) {
        abortControllerRef.current.abort();
        abortControllerRef.current = null;
      }

      if (streamRef.current) {
        console.log('ğŸ›‘ åœæ­¢åª’ä½“æµè½¨é“...');
        streamRef.current.getTracks().forEach(track => {
          track.stop();
          track.enabled = false;
        });
        streamRef.current = null;
      }

      if (analyserRef.current) {
        analyserRef.current.disconnect();
        analyserRef.current = null;
      }

      if (audioContextRef.current) {
        console.log('ğŸ”‡ å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡...');
        if (audioContextRef.current.state !== 'closed') {
          await audioContextRef.current.close();
        }
        audioContextRef.current = null;
      }

      pcmDataRef.current = [];
      dataArrayRef.current = null;

      // é‡ç½®è¯­éŸ³æ´»åŠ¨æ£€æµ‹
      voiceActivityRef.current = {
        hasSpeech: false,
        speechStartTime: 0,
        totalSamples: 0,
        silentSamples: 0,
        speechThreshold: 0.015,
        minSpeechDuration: 800
      };

    } catch (error) {
      console.warn('èµ„æºæ¸…ç†é”™è¯¯:', error);
    } finally {
      setListening(false);
      setIsProcessing(false);
      setStatus('idle');
      setAudioLevel(0);
      audioLevelRef.current = 0;
      lastUpdateTimeRef.current = 0;
      console.log('âœ… èµ„æºæ¸…ç†å®Œæˆ');
    }
  }, []);

  // ä¼˜åŒ–çš„éŸ³é¢‘å¤„ç†è®¾ç½®
  const setupAudioProcessing = useCallback(async (stream) => {
    try {
      console.log('ğŸµ å¼€å§‹è®¾ç½®éŸ³é¢‘å¤„ç†...');

      const AudioContext = window.AudioContext || window.webkitAudioContext;
      const audioContext = new AudioContext({ 
        sampleRate: 16000,
        latencyHint: 'interactive'
      });
      audioContextRef.current = audioContext;

      // ç¡®ä¿éŸ³é¢‘ä¸Šä¸‹æ–‡æ˜¯æ´»è·ƒçŠ¶æ€
      if (audioContext.state === 'suspended') {
        console.log('â¸ï¸ éŸ³é¢‘ä¸Šä¸‹æ–‡è¢«æŒ‚èµ·ï¼Œå°è¯•æ¢å¤...');
        await audioContext.resume();
      }

      console.log('âœ… éŸ³é¢‘ä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ:', audioContext.state);

      const mediaStreamSource = audioContext.createMediaStreamSource(stream);
      
      // å¢å¼ºéŸ³é¢‘å¤„ç†é“¾
      // 1. é«˜é€šæ»¤æ³¢å™¨ - å»é™¤ä½é¢‘å™ªéŸ³
      const highPassFilter = audioContext.createBiquadFilter();
      highPassFilter.type = 'highpass';
      highPassFilter.frequency.value = 80;
      
      // 2. ä½é€šæ»¤æ³¢å™¨ - å»é™¤é«˜é¢‘å™ªéŸ³
      const lowPassFilter = audioContext.createBiquadFilter();
      lowPassFilter.type = 'lowpass';
      lowPassFilter.frequency.value = 4000;
      
      // 3. åŠ¨æ€å‹ç¼©å™¨ - å¹³è¡¡éŸ³é‡
      const compressor = audioContext.createDynamicsCompressor();
      compressor.threshold.value = -24;
      compressor.knee.value = 30;
      compressor.ratio.value = 12;
      compressor.attack.value = 0.003;
      compressor.release.value = 0.25;
      
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 512;
      analyser.smoothingTimeConstant = 0.2;
      analyserRef.current = analyser;
      
      // è¿æ¥å®Œæ•´çš„éŸ³é¢‘å¤„ç†é“¾
      mediaStreamSource.connect(highPassFilter);
      highPassFilter.connect(lowPassFilter);
      lowPassFilter.connect(compressor);
      compressor.connect(analyser);
      
      const bufferLength = analyser.frequencyBinCount;
      dataArrayRef.current = new Float32Array(bufferLength);
      
      processingActiveRef.current = true;
      lastUpdateTimeRef.current = Date.now();
      
      // é‡ç½®è¯­éŸ³æ´»åŠ¨æ£€æµ‹
      voiceActivityRef.current = {
        hasSpeech: false,
        speechStartTime: 0,
        totalSamples: 0,
        silentSamples: 0,
        speechThreshold: 0.015,
        minSpeechDuration: 800
      };
      
      // ä¼˜åŒ–çš„éŸ³é¢‘å¤„ç†å¾ªç¯
      const processAudio = () => {
        if (!processingActiveRef.current || !isMountedRef.current) {
          return;
        }
        
        try {
          const dataArray = dataArrayRef.current;
          analyser.getFloatTimeDomainData(dataArray);
          
          // æ”¹è¿›çš„éŸ³é‡è®¡ç®— - ä½¿ç”¨èƒ½é‡è®¡ç®—
          let sumSquares = 0;
          let peak = 0;
          for (let i = 0; i < dataArray.length; i++) {
            const value = dataArray[i];
            sumSquares += value * value;
            if (Math.abs(value) > peak) peak = Math.abs(value);
          }
          
          const rms = Math.sqrt(sumSquares / dataArray.length);
          const volume = Math.max(rms, peak * 0.5);
          
          audioLevelRef.current = Math.min(100, volume * 800);

          // è¯­éŸ³æ´»åŠ¨æ£€æµ‹
          const isSpeech = volume > voiceActivityRef.current.speechThreshold;
          const now = Date.now();
          
          if (isSpeech) {
            if (!voiceActivityRef.current.hasSpeech) {
              voiceActivityRef.current.hasSpeech = true;
              voiceActivityRef.current.speechStartTime = now;
              console.log('ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨');
            }
            voiceActivityRef.current.silentSamples = 0;
          } else {
            voiceActivityRef.current.silentSamples += dataArray.length;
          }
          
          voiceActivityRef.current.totalSamples += dataArray.length;

          // è½¬æ¢ä¸ºPCM - ä¼˜åŒ–åŠ¨æ€èŒƒå›´
          const pcmData = new Int16Array(dataArray.length);
          const compressionFactor = 1.5;
          
          for (let i = 0; i < dataArray.length; i++) {
            let s = Math.max(-1, Math.min(1, dataArray[i]));
            s = Math.sign(s) * Math.min(1, Math.abs(s) * compressionFactor);
            pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }

          // è°ƒæ•´ä¿å­˜æ•°æ®çš„é˜ˆå€¼
          if (audioLevelRef.current > 2) {
            pcmDataRef.current.push(pcmData);
          }

          // é™åˆ¶ç¼“å†²åŒºå¤§å°
          if (pcmDataRef.current.length > 400) {
            pcmDataRef.current = pcmDataRef.current.slice(-300);
          }

          // æ›´æ–°éŸ³é¢‘ç”µå¹³
          const currentTime = Date.now();
          if (currentTime - lastUpdateTimeRef.current > 150) {
            setAudioLevel(Math.round(audioLevelRef.current));
            lastUpdateTimeRef.current = currentTime;
          }

          if (processingActiveRef.current && isMountedRef.current) {
            animationFrameRef.current = requestAnimationFrame(processAudio);
          }
        } catch (error) {
          console.error('éŸ³é¢‘å¤„ç†é”™è¯¯:', error);
          processingActiveRef.current = false;
        }
      };
      
      animationFrameRef.current = requestAnimationFrame(processAudio);
      setAudioMethod('enhanced-analyser');
      console.log('âœ… éŸ³é¢‘å¤„ç†è®¾ç½®å®Œæˆ - å¢å¼ºæ¨¡å¼');
      
      return 'enhanced-analyser';
    } catch (error) {
      console.error('âŒ éŸ³é¢‘å¤„ç†è®¾ç½®å¤±è´¥:', error);
      throw error;
    }
  }, []);

  // æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è¯­éŸ³è¾“å…¥
  const hasValidSpeechInput = useCallback(() => {
    const dataLength = pcmDataRef.current.reduce((sum, data) => sum + data.length, 0);
    const voiceActivity = voiceActivityRef.current;
    
    console.log('ğŸ” æ£€æŸ¥è¯­éŸ³è¾“å…¥æœ‰æ•ˆæ€§:', {
      totalSamples: dataLength,
      hasSpeech: voiceActivity.hasSpeech,
      speechDuration: voiceActivity.hasSpeech ? Date.now() - voiceActivity.speechStartTime : 0,
      silentRatio: voiceActivity.totalSamples > 0 ? (voiceActivity.silentSamples / voiceActivity.totalSamples).toFixed(2) : 1
    });

    // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¯­éŸ³æ•°æ®
    if (dataLength === 0) {
      return { valid: false, reason: 'æ²¡æœ‰æ£€æµ‹åˆ°éŸ³é¢‘æ•°æ®' };
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰è¯­éŸ³æ´»åŠ¨
    if (!voiceActivity.hasSpeech) {
      return { valid: false, reason: 'æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨' };
    }

    // æ£€æŸ¥è¯­éŸ³æŒç»­æ—¶é—´æ˜¯å¦è¶³å¤Ÿ
    const speechDuration = Date.now() - voiceActivity.speechStartTime;
    if (speechDuration < voiceActivity.minSpeechDuration) {
      return { 
        valid: false, 
        reason: `è¯­éŸ³å¤ªçŸ­ (${speechDuration}ms)ï¼Œè¯·è‡³å°‘è¯´è¯${voiceActivity.minSpeechDuration}ms` 
      };
    }

    // æ£€æŸ¥é™éŸ³æ¯”ä¾‹
    const silentRatio = voiceActivity.totalSamples > 0 ? voiceActivity.silentSamples / voiceActivity.totalSamples : 1;
    if (silentRatio > 0.95) {
      return { 
        valid: false, 
        reason: 'è¯­éŸ³ä¿¡å·å¤ªå¼±ï¼Œè¯·é è¿‘éº¦å…‹é£è¯´è¯' 
      };
    }

    return { valid: true };
  }, []);

  // å¤„ç†éŸ³é¢‘æ•°æ® - æŒ‰ç…§ç™¾åº¦å®˜æ–¹ç¤ºä¾‹
  const processAndSendAudio = useCallback(async (pcmDataArray) => {
    try {
      console.log('ğŸµ å¼€å§‹å¤„ç†PCMéŸ³é¢‘æ•°æ®...');
      
      if (!pcmDataArray || pcmDataArray.length === 0) {
        throw new Error('æ²¡æœ‰PCMæ•°æ®éœ€è¦å¤„ç†');
      }

      // åˆå¹¶æ‰€æœ‰PCMæ•°æ®å—
      const totalSamples = pcmDataArray.reduce((sum, data) => sum + data.length, 0);
      const mergedPcmData = new Int16Array(totalSamples);
      let offset = 0;
      pcmDataArray.forEach(data => {
        if (data && data.length) {
          mergedPcmData.set(data, offset);
          offset += data.length;
        }
      });

      // æ£€æŸ¥éŸ³é¢‘é•¿åº¦
      const minSamples = 16000 * 0.8; // è‡³å°‘0.8ç§’
      if (totalSamples < minSamples) {
        throw new Error(`è¯­éŸ³å¤ªçŸ­ï¼Œè¯·è‡³å°‘å½•åˆ¶0.8ç§’ (å½“å‰: ${(totalSamples / 16000).toFixed(2)}s)`);
      }

      console.log(`ğŸ“¤ å‡†å¤‡å‘é€PCMæ•°æ®åˆ°ç™¾åº¦API: ${mergedPcmData.length} é‡‡æ ·ç‚¹`);

      // å°†PCMæ•°æ®è½¬æ¢ä¸ºbase64
      const base64Audio = arrayBufferToBase64(mergedPcmData.buffer);

      // æŒ‰ç…§ç™¾åº¦å®˜æ–¹ç¤ºä¾‹æ„é€ è¯·æ±‚æ•°æ®
      const requestData = {
        format: 'pcm',
        rate: 16000,
        channel: 1,
        cuid: generateCuid(),
        token: await getBaiduToken(),
        speech: base64Audio,
        len: mergedPcmData.length * 2 // PCMæ•°æ®é•¿åº¦ï¼ˆå­—èŠ‚æ•°ï¼‰
      };

      console.log('ğŸ”„ å‘é€è¯·æ±‚åˆ°ç™¾åº¦è¯­éŸ³è¯†åˆ«API...', {
        dataLength: base64Audio.length,
        sampleCount: mergedPcmData.length,
        cuid: requestData.cuid
      });

      abortControllerRef.current = new AbortController();

      const response = await fetch('/api/speech-proxy', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify(requestData),
        signal: abortControllerRef.current.signal
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`æœåŠ¡å™¨é”™è¯¯: ${response.status} - ${errorText}`);
      }

      const result = await response.json();

      // å¤„ç†ç™¾åº¦APIå“åº”
      if (result.err_no === 0) {
        console.log('âœ… ç™¾åº¦è¯­éŸ³è¯†åˆ«æˆåŠŸ:', result.result);
        return result.result[0]; // ç™¾åº¦è¿”å›çš„æ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªç»“æœ
      } else {
        throw new Error(`ç™¾åº¦è¯†åˆ«é”™è¯¯: ${result.err_msg} (${result.err_no})`);
      }

    } catch (error) {
      console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      
      // ç™¾åº¦é”™è¯¯ç æ˜ å°„
      const errorMap = {
        3300: 'éŸ³é¢‘è´¨é‡è¿‡å·®',
        3301: 'éŸ³é¢‘è´¨é‡è¿‡å·®',
        3302: 'éŸ³é¢‘è¿‡çŸ­',
        3303: 'éŸ³é¢‘è§£ç å¤±è´¥',
        3304: 'æœåŠ¡ç«¯å¤„ç†å¤±è´¥',
        3305: 'éŸ³é¢‘è¿‡é•¿',
        3307: 'éŸ³é¢‘æ•°æ®é—®é¢˜',
        3308: 'éŸ³é¢‘é‡‡æ ·ç‡ä¸æ­£ç¡®',
        3309: 'éŸ³é¢‘ä½æ·±ä¸æ­£ç¡®',
        3310: 'éŸ³é¢‘å£°é“æ•°ä¸æ­£ç¡®',
        3311: 'éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒ',
        3312: 'éŸ³é¢‘éŸ³é‡è¿‡å°'
      };
      
      let userFriendlyError = error.message;
      
      // å¦‚æœæ˜¯ç™¾åº¦é”™è¯¯ç ï¼Œæä¾›å‹å¥½æç¤º
      if (error.message.includes('err_no')) {
        const errNoMatch = error.message.match(/\((\d+)\)/);
        if (errNoMatch) {
          const errNo = errNoMatch[1];
          userFriendlyError = errorMap[errNo] || `è¯†åˆ«å¤±è´¥ (é”™è¯¯ç : ${errNo})`;
        }
      }
      
      throw new Error(userFriendlyError);
    } finally {
      abortControllerRef.current = null;
    }
  }, []);

  // å¼€å§‹ç›‘å¬ - ä¼˜åŒ–ç‰ˆæœ¬
  const startListening = useCallback(async () => {
    if (listening || isProcessing) {
      console.log('â¸ï¸ å·²åœ¨ç›‘å¬ä¸­ï¼Œè·³è¿‡');
      return false;
    }

    if (!checkBrowserSupport()) {
      setError('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½');
      return false;
    }

    // è®¾ç½®å¯åŠ¨è¶…æ—¶ï¼ˆ5ç§’ï¼‰
    startTimeoutRef.current = setTimeout(() => {
      if (status === 'starting') {
        console.error('ğŸš¨ å¯åŠ¨è¶…æ—¶ï¼Œå¼ºåˆ¶æ¸…ç†èµ„æº');
        setError('å¯åŠ¨è¶…æ—¶ï¼Œè¯·é‡è¯•');
        cleanupAudioResources();
      }
    }, 5000);

    try {
      console.log('ğŸš€ å¼€å§‹è¯­éŸ³è¯†åˆ«æµç¨‹...');
      setListening(true);
      setIsProcessing(false);
      setError(null);
      setTranscript('');
      setFinalTranscript('');
      setStatus('starting');
      pcmDataRef.current = [];
      audioLevelRef.current = 0;
      lastUpdateTimeRef.current = 0;
      isStoppingRef.current = false;

      // é‡ç½®è¯­éŸ³æ´»åŠ¨æ£€æµ‹
      voiceActivityRef.current = {
        hasSpeech: false,
        speechStartTime: 0,
        totalSamples: 0,
        silentSamples: 0,
        speechThreshold: 0.015,
        minSpeechDuration: 800
      };

      console.log('ğŸ¤ è¯·æ±‚éº¦å…‹é£æƒé™...');

      // ä¼˜åŒ–éŸ³é¢‘é…ç½® - æé«˜è¯­éŸ³è´¨é‡
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,
          sampleRate: 16000,
          sampleSize: 16,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          googEchoCancellation: true,
          googAutoGainControl: true,
          googNoiseSuppression: true,
          googHighpassFilter: true,
          latency: 0
        },
        video: false
      }).catch(error => {
        console.error('éº¦å…‹é£æƒé™è·å–å¤±è´¥:', error);
        throw error;
      });

      console.log('âœ… éº¦å…‹é£æƒé™è·å–æˆåŠŸ');
      setPermissionState('granted');
      streamRef.current = stream;

      console.log('ğŸ”§ è®¾ç½®éŸ³é¢‘å¤„ç†...');
      await setupAudioProcessing(stream);

      // æ¸…é™¤å¯åŠ¨è¶…æ—¶
      if (startTimeoutRef.current) {
        clearTimeout(startTimeoutRef.current);
        startTimeoutRef.current = null;
      }

      setStatus('listening');
      console.log('âœ… è¯­éŸ³è¯†åˆ«å¯åŠ¨æˆåŠŸ - ä¼˜åŒ–é…ç½®');
      return true;

    } catch (error) {
      console.error('âŒ å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      
      // æ¸…é™¤å¯åŠ¨è¶…æ—¶
      if (startTimeoutRef.current) {
        clearTimeout(startTimeoutRef.current);
        startTimeoutRef.current = null;
      }

      let errorMessage = 'å¯åŠ¨å¤±è´¥ï¼Œè¯·é‡è¯•';
      
      if (error.name === 'NotAllowedError') {
        setPermissionState('denied');
        errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£è®¿é—®';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«';
      } else if (error.name === 'NotReadableError') {
        errorMessage = 'éº¦å…‹é£è®¾å¤‡è¢«å ç”¨';
      }
      
      setError(errorMessage);
      setStatus('error');
      await cleanupAudioResources();
      return false;
    }
  }, [listening, isProcessing, checkBrowserSupport, setupAudioProcessing, cleanupAudioResources, status]);

  // åœæ­¢ç›‘å¬ - å¢å¼ºç‰ˆæœ¬
  const stopListening = useCallback(async () => {
    if (!listening || isStoppingRef.current) {
      console.log('â¸ï¸ æœªåœ¨ç›‘å¬ä¸­æˆ–æ­£åœ¨åœæ­¢ï¼Œæ— éœ€åœæ­¢');
      return null;
    }

    console.log('ğŸ›‘ ç«‹å³åœæ­¢è¯­éŸ³å½•éŸ³...');
    setStatus('processing');
    setIsProcessing(true);
    isStoppingRef.current = true;

    try {
      // ç«‹å³åœæ­¢éŸ³é¢‘å¤„ç†
      processingActiveRef.current = false;
      
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      // æ£€æŸ¥è¯­éŸ³è¾“å…¥æœ‰æ•ˆæ€§
      const speechCheck = hasValidSpeechInput();
      if (!speechCheck.valid) {
        console.log(`âŒ è¯­éŸ³è¾“å…¥æ— æ•ˆ: ${speechCheck.reason}`);
        throw new Error(speechCheck.reason);
      }

      // ç«‹å³å¤„ç†å½“å‰æ”¶é›†çš„éŸ³é¢‘æ•°æ®ï¼Œä¸ç­‰å¾…
      const dataLength = pcmDataRef.current.reduce((sum, data) => sum + data.length, 0);
      console.log(`ğŸ“Š å¤„ç†å½•éŸ³æ•°æ®: ${dataLength} é‡‡æ ·ç‚¹`);
      
      if (dataLength === 0) {
        throw new Error('æ²¡æœ‰æ£€æµ‹åˆ°éŸ³é¢‘æ•°æ®');
      }

      // æ·»åŠ é‡è¯•æœºåˆ¶
      let retries = 2;
      let lastError = null;
      
      while (retries >= 0) {
        try {
          const result = await processAndSendAudio(pcmDataRef.current);
          
          if (result) {
            setFinalTranscript(result);
            setTranscript(result);
            options.onResult?.(result);
            console.log('âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ:', result);
            return result;
          }
        } catch (error) {
          lastError = error;
          console.warn(`âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥ (å‰©ä½™é‡è¯•æ¬¡æ•°: ${retries}):`, error.message);
          
          if (retries > 0 && error.message.includes('éŸ³é¢‘è´¨é‡è¿‡ä½')) {
            // ç­‰å¾…çŸ­æš‚æ—¶é—´åé‡è¯•
            await new Promise(resolve => setTimeout(resolve, 500));
            retries--;
          } else {
            break;
          }
        }
      }
      
      throw lastError;

    } catch (error) {
      console.error('âŒ è¯­éŸ³è¯†åˆ«æœ€ç»ˆå¤±è´¥:', error);
      setError(error.message);
      options.onError?.(error);
      return null;

    } finally {
      await cleanupAudioResources();
    }
  }, [listening, processAndSendAudio, cleanupAudioResources, options, hasValidSpeechInput]);

  // ä¸­æ­¢è¯†åˆ«
  const abort = useCallback(() => {
    console.log('ğŸš« ä¸­æ­¢è¯­éŸ³è¯†åˆ«');
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
    cleanupAudioResources();
  }, [cleanupAudioResources]);

  // é‡ç½®çŠ¶æ€
  const resetTranscript = useCallback(() => {
    setTranscript('');
    setFinalTranscript('');
    setError(null);
    setAudioLevel(0);
    audioLevelRef.current = 0;
  }, []);

  // ç»„ä»¶å¸è½½æ¸…ç†
  useEffect(() => {
    return () => {
      isMountedRef.current = false;
      cleanupAudioResources();
    };
  }, [cleanupAudioResources]);

  return {
    // çŠ¶æ€
    listening,
    transcript,
    interimTranscript: transcript,
    finalTranscript,
    error,
    isProcessing,
    status,
    audioLevel,
    permissionState,
    audioMethod,
    
    // æ–¹æ³•
    startListening,
    stopListening,
    abort,
    resetTranscript,
    
    // æ”¯æŒä¿¡æ¯
    isSupported: checkBrowserSupport(),
    browserSupportsSpeechRecognition: checkBrowserSupport(),
    platform: 'baidu'
  };
};

export default useBaiduSpeechRecognition;