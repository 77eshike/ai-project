// src/hooks/useMobileSpeech.js
import { useState, useCallback, useEffect, useRef } from 'react';
import { 
  getDeviceInfo, 
  checkSpeechSupport, 
  checkMicrophonePermission,
  requestMicrophonePermission 
} from '../components/Utils/deviceUtils';

export const useMobileSpeech = (voiceEnabled = true) => {
  const [voiceState, setVoiceState] = useState({
    isListening: false,
    transcript: '',
    finalTranscript: '',
    isSupported: false,
    permissionState: 'prompt',
    status: 'idle',
    supportLevel: 'none',
    waitingForPermission: false,
    deviceInfo: {}
  });
  
  const [voiceError, setVoiceError] = useState(null);
  const [isPressing, setIsPressing] = useState(false);
  const recognitionRef = useRef(null);
  const isStoppingRef = useRef(false);
  const recognitionTimeoutRef = useRef(null);
  const noSpeechTimeoutRef = useRef(null);
  const hasReceivedResultRef = useRef(false);

  // å…ˆå®šä¹‰ stopVoiceInputï¼Œç¡®ä¿å®ƒåœ¨å…¶ä»–å‡½æ•°ä¹‹å‰å¯ç”¨
  const stopVoiceInput = useCallback(() => {
    if (!recognitionRef.current || !voiceState.isListening || isStoppingRef.current) {
      return;
    }

    console.log('ðŸ”´ åœæ­¢è¯­éŸ³è¾“å…¥');
    isStoppingRef.current = true;

    // æ¸…é™¤è¶…æ—¶
    if (noSpeechTimeoutRef.current) {
      clearTimeout(noSpeechTimeoutRef.current);
      noSpeechTimeoutRef.current = null;
    }

    try {
      recognitionRef.current.stop();
      console.log('âœ… è¯­éŸ³è¯†åˆ«åœæ­¢æˆåŠŸ');
    } catch (error) {
      console.error('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      // å¦‚æžœåœæ­¢å¤±è´¥ï¼Œå¼ºåˆ¶ç»“æŸ
      isStoppingRef.current = false;
      setVoiceState(prev => ({
        ...prev,
        isListening: false,
        status: 'idle'
      }));
    }
  }, [voiceState.isListening]);

  const handleSpeechError = useCallback((error) => {
    isStoppingRef.current = false;
    setIsPressing(false);

    // æ¸…é™¤è¶…æ—¶
    if (noSpeechTimeoutRef.current) {
      clearTimeout(noSpeechTimeoutRef.current);
      noSpeechTimeoutRef.current = null;
    }

    let errorMessage = 'è¯­éŸ³è¯†åˆ«é”™è¯¯';
    let permissionState = voiceState.permissionState;

    switch (error) {
      case 'not-allowed':
      case 'permission-denied':
        errorMessage = 'éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ã€‚è¯·å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£Žã€‚';
        permissionState = 'denied';
        break;
      case 'no-speech':
        errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥ã€‚è¯·é è¿‘éº¦å…‹é£Žè¯´è¯æˆ–æ£€æŸ¥éº¦å…‹é£Žè®¾ç½®ã€‚';
        break;
      case 'audio-capture':
        errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£Žè®¾å¤‡ã€‚è¯·æ£€æŸ¥è®¾å¤‡è¿žæŽ¥ã€‚';
        break;
      case 'network':
        errorMessage = 'ç½‘ç»œè¿žæŽ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåŽé‡è¯•ã€‚';
        break;
      case 'service-not-allowed':
        errorMessage = 'è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨ã€‚';
        break;
      case 'aborted':
        errorMessage = 'è¯­éŸ³è¯†åˆ«è¢«ä¸­æ­¢ã€‚';
        break;
      case 'language-not-supported':
        errorMessage = 'ä¸æ”¯æŒä¸­æ–‡è¯­éŸ³è¯†åˆ«ã€‚';
        break;
      default:
        errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${error}`;
    }

    console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', error, errorMessage);
    setVoiceError(errorMessage);
    setVoiceState(prev => ({
      ...prev,
      isListening: false,
      status: 'error',
      permissionState
    }));
  }, [voiceState.permissionState]);

  // ä½¿ç”¨ç»Ÿä¸€çš„è®¾å¤‡æ£€æµ‹
  useEffect(() => {
    const deviceInfo = getDeviceInfo();
    const speechSupport = checkSpeechSupport();
    
    console.log('ðŸ“± ç§»åŠ¨ç«¯è®¾å¤‡æ£€æµ‹:', {
      deviceInfo,
      speechSupport,
      userAgent: navigator.userAgent
    });

    setVoiceState(prev => ({
      ...prev,
      isSupported: speechSupport.supported,
      supportLevel: speechSupport.supportLevel,
      deviceInfo
    }));

    if (!speechSupport.speechRecognitionSupported) {
      setVoiceError('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚è¯·ä½¿ç”¨Chromeã€Safariæˆ–Edgeæµè§ˆå™¨ã€‚');
      return;
    }

    // æ£€æŸ¥éº¦å…‹é£Žæƒé™çŠ¶æ€
    checkMicrophonePermission().then(permissionState => {
      console.log('ðŸŽ¤ åˆå§‹æƒé™çŠ¶æ€:', permissionState);
      setVoiceState(prev => ({ ...prev, permissionState }));
    });

    // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
    initializeSpeechRecognition();
    
    // æ¸…ç†å‡½æ•°
    return () => {
      if (recognitionTimeoutRef.current) {
        clearTimeout(recognitionTimeoutRef.current);
      }
      if (noSpeechTimeoutRef.current) {
        clearTimeout(noSpeechTimeoutRef.current);
      }
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (error) {
          // å¿½ç•¥æ¸…ç†é”™è¯¯
        }
      }
    };
  }, []);

  const initializeSpeechRecognition = useCallback(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      console.error('âŒ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«API');
      setVoiceError('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚è¯·ä½¿ç”¨Chromeã€Safariæˆ–Edgeæµè§ˆå™¨ã€‚');
      return;
    }

    try {
      recognitionRef.current = new SpeechRecognition();
      const recognition = recognitionRef.current;

      console.log('ðŸ”§ åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«é…ç½®');

      // å…³é”®ä¿®å¤ï¼šä¼˜åŒ–é…ç½®
      recognition.continuous = false;  // æ”¹ä¸ºéžè¿žç»­æ¨¡å¼
      recognition.interimResults = true;
      recognition.lang = 'zh-CN';
      recognition.maxAlternatives = 1;
      
      // ç§»åŠ¨ç«¯ç‰¹å®šè®¾ç½®
      if (voiceState.deviceInfo.isMobile) {
        recognition.continuous = false; // ç§»åŠ¨ç«¯ä½¿ç”¨å•æ¬¡è¯†åˆ«
        recognition.interimResults = true;
        recognition.maxAlternatives = 3;
        
        // å°è¯•ä¸åŒçš„è¯­è¨€å˜ä½“
        const languages = ['zh-CN', 'zh-TW', 'zh-HK', 'cmn-Hans-CN', 'cmn-Hant-TW'];
        for (const lang of languages) {
          try {
            recognition.lang = lang;
            console.log(`âœ… è¯­è¨€è®¾ç½®æˆåŠŸ: ${lang}`);
            break;
          } catch (e) {
            console.log(`âŒ è¯­è¨€è®¾ç½®å¤±è´¥: ${lang}`);
          }
        }
      }

      recognition.onstart = () => {
        console.log('ðŸŽ¤ è¯­éŸ³è¯†åˆ«å¼€å§‹ - ç­‰å¾…è¯­éŸ³è¾“å…¥');
        isStoppingRef.current = false;
        setIsPressing(false);
        hasReceivedResultRef.current = false;
        
        setVoiceState(prev => ({
          ...prev,
          isListening: true,
          status: 'listening',
          transcript: 'æ­£åœ¨è†å¬...è¯·å¼€å§‹è¯´è¯',
          finalTranscript: '',
          waitingForPermission: false
        }));
        setVoiceError(null);

        // è®¾ç½®è¯­éŸ³æ£€æµ‹è¶…æ—¶ï¼ˆ8ç§’ï¼‰
        noSpeechTimeoutRef.current = setTimeout(() => {
          if (voiceState.isListening && !hasReceivedResultRef.current) {
            console.log('â° è¯­éŸ³æ£€æµ‹è¶…æ—¶ - æœªæ”¶åˆ°ä»»ä½•éŸ³é¢‘è¾“å…¥');
            setVoiceError('æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥ã€‚è¯·æ£€æŸ¥éº¦å…‹é£Žå¹¶ç¡®ä¿åœ¨å®‰é™çŽ¯å¢ƒä¸­è¯´è¯ã€‚');
            stopVoiceInput();
          }
        }, 8000);
      };

      recognition.onresult = (event) => {
        if (isStoppingRef.current) return;

        hasReceivedResultRef.current = true;
        
        console.log('ðŸ”Š æ”¶åˆ°è¯­éŸ³è¯†åˆ«ç»“æžœ', {
          resultsLength: event.results.length,
          resultIndex: event.resultIndex
        });

        let interimTranscript = '';
        let finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          const transcript = result[0].transcript;
          const confidence = result[0].confidence;
          
          console.log(`ðŸ—£ï¸ è¯†åˆ«ç»“æžœ ${i}:`, {
            transcript,
            isFinal: result.isFinal,
            confidence
          });

          if (result.isFinal) {
            finalTranscript += transcript;
            console.log('âœ… æœ€ç»ˆè¯†åˆ«ç»“æžœ:', transcript);
          } else {
            interimTranscript += transcript;
            console.log('â³ ä¸´æ—¶è¯†åˆ«ç»“æžœ:', transcript);
          }
        }

        setVoiceState(prev => ({
          ...prev,
          transcript: interimTranscript || 'è¯†åˆ«ä¸­...',
          finalTranscript: prev.finalTranscript + finalTranscript
        }));

        // æ¸…é™¤æ— è¯­éŸ³è¶…æ—¶
        if (noSpeechTimeoutRef.current && (interimTranscript || finalTranscript)) {
          clearTimeout(noSpeechTimeoutRef.current);
          noSpeechTimeoutRef.current = null;
        }

        // å¦‚æžœæœ‰æœ€ç»ˆç»“æžœï¼Œè‡ªåŠ¨åœæ­¢
        if (finalTranscript) {
          console.log('ðŸŽ‰ è¯†åˆ«å®Œæˆï¼Œè‡ªåŠ¨åœæ­¢');
          setTimeout(() => {
            if (voiceState.isListening) {
              stopVoiceInput();
            }
          }, 1000);
        }
      };

      recognition.onerror = (event) => {
        console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯è¯¦æƒ…:', {
          error: event.error,
          message: event.message,
          type: event.type
        });
        handleSpeechError(event.error);
      };

      recognition.onend = () => {
        console.log('ðŸ”š è¯­éŸ³è¯†åˆ«ç»“æŸ');
        isStoppingRef.current = false;
        setIsPressing(false);
        
        // æ¸…é™¤è¶…æ—¶
        if (noSpeechTimeoutRef.current) {
          clearTimeout(noSpeechTimeoutRef.current);
          noSpeechTimeoutRef.current = null;
        }
        
        setVoiceState(prev => ({
          ...prev,
          isListening: false,
          status: 'idle',
          transcript: ''
        }));
      };

      recognition.onaudiostart = () => {
        console.log('ðŸ”Š éŸ³é¢‘è¾“å…¥å¼€å§‹ - éº¦å…‹é£Žå·²æ¿€æ´»');
      };

      recognition.onaudioend = () => {
        console.log('ðŸ”Š éŸ³é¢‘è¾“å…¥ç»“æŸ');
      };

      recognition.onsoundstart = () => {
        console.log('ðŸŽµ æ£€æµ‹åˆ°å£°éŸ³è¾“å…¥');
        setVoiceState(prev => ({
          ...prev,
          transcript: 'æ£€æµ‹åˆ°å£°éŸ³...æ­£åœ¨è¯†åˆ«'
        }));
      };

      recognition.onsoundend = () => {
        console.log('ðŸŽµ å£°éŸ³è¾“å…¥ç»“æŸ');
      };

      recognition.onnomatch = () => {
        console.log('â“ æ²¡æœ‰åŒ¹é…çš„è¯†åˆ«ç»“æžœ');
        setVoiceState(prev => ({
          ...prev,
          transcript: 'æœªèƒ½è¯†åˆ«è¯­éŸ³ï¼Œè¯·é‡è¯•'
        }));
      };

      console.log('âœ… è¯­éŸ³è¯†åˆ«é…ç½®å®Œæˆ');

    } catch (error) {
      console.error('âŒ åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      setVoiceError(`åˆå§‹åŒ–å¤±è´¥: ${error.message}`);
    }
  }, [voiceState.deviceInfo, voiceState.isListening, handleSpeechError, stopVoiceInput]);

  const startVoiceInput = useCallback(async () => {
    if (!recognitionRef.current) {
      console.error('âŒ è¯­éŸ³è¯†åˆ«æœªåˆå§‹åŒ–');
      setVoiceError('è¯­éŸ³è¯†åˆ«æœªåˆå§‹åŒ–ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•');
      return;
    }

    if (voiceState.isListening) {
      console.log('âš ï¸ å·²åœ¨ç›‘å¬ä¸­ï¼Œå¿½ç•¥é‡å¤å¯åŠ¨');
      return;
    }

    // æ¸…é™¤ä¹‹å‰çš„è¶…æ—¶
    if (recognitionTimeoutRef.current) {
      clearTimeout(recognitionTimeoutRef.current);
    }
    if (noSpeechTimeoutRef.current) {
      clearTimeout(noSpeechTimeoutRef.current);
    }

    // å®žæ—¶æ£€æŸ¥æƒé™
    const currentPermission = await checkMicrophonePermission();
    console.log('ðŸ” å®žæ—¶æƒé™æ£€æŸ¥:', currentPermission);
    
    if (currentPermission !== 'granted') {
      setVoiceError(`éº¦å…‹é£Žæƒé™: ${currentPermission}ã€‚è¯·æŽˆæƒåŽé‡è¯•ã€‚`);
      setVoiceState(prev => ({ ...prev, permissionState: currentPermission }));
      return;
    }

    console.log('ðŸŸ¢ å¼€å§‹è¯­éŸ³è¾“å…¥');
    setIsPressing(true);
    setVoiceState(prev => ({
      ...prev,
      transcript: 'å¯åŠ¨ä¸­...',
      finalTranscript: ''
    }));
    setVoiceError(null);
    isStoppingRef.current = false;
    hasReceivedResultRef.current = false;

    try {
      await recognitionRef.current.start();
      console.log('âœ… è¯­éŸ³è¯†åˆ«å¯åŠ¨æˆåŠŸ');
    } catch (error) {
      console.error('âŒ å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      setIsPressing(false);
      
      // å¦‚æžœæ˜¯ abort é”™è¯¯ï¼Œå»¶è¿Ÿé‡è¯•
      if (error.toString().includes('abort') || error.toString().includes('started')) {
        console.log('ðŸ”„ è¯†åˆ«å™¨å¿™ç¢Œï¼Œå»¶è¿Ÿé‡è¯•');
        recognitionTimeoutRef.current = setTimeout(() => {
          startVoiceInput();
        }, 1000);
      } else {
        handleSpeechError(error.name || 'start-failed');
      }
    }
  }, [voiceState.isListening, handleSpeechError]);

  const clearVoiceError = useCallback(() => {
    setVoiceError(null);
  }, []);

  // ç§»åŠ¨ç«¯å¿«é€Ÿæµ‹è¯•
  const mobileQuickTest = useCallback(async () => {
    console.log('ðŸ§ª ç§»åŠ¨ç«¯å¿«é€Ÿæµ‹è¯•å¼€å§‹');
    setVoiceError(null);

    try {
      // æµ‹è¯•éº¦å…‹é£Žæƒé™
      const permission = await checkMicrophonePermission();
      console.log('ðŸŽ¤ éº¦å…‹é£Žæƒé™:', permission);
      
      // æµ‹è¯•è¯­éŸ³æ”¯æŒ
      const support = checkSpeechSupport();
      console.log('ðŸ”Š è¯­éŸ³æ”¯æŒ:', support);

      setVoiceState(prev => ({ 
        ...prev, 
        permissionState: permission,
        isSupported: support.supported,
        supportLevel: support.supportLevel
      }));

      // æµ‹è¯•è¯­éŸ³è¯†åˆ«
      if (support.speechRecognitionSupported && permission === 'granted') {
        console.log('ðŸŽ¯ å¼€å§‹è¯­éŸ³è¯†åˆ«æµ‹è¯•');
        await startVoiceInput();
        
        // 5ç§’åŽè‡ªåŠ¨åœæ­¢æµ‹è¯•
        setTimeout(() => {
          if (voiceState.isListening) {
            console.log('â° æµ‹è¯•æ—¶é—´åˆ°ï¼Œåœæ­¢è¯†åˆ«');
            stopVoiceInput();
          }
        }, 5000);
      } else {
        const errorMsg = !support.speechRecognitionSupported ? 
          'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«' : 
          `éº¦å…‹é£Žæƒé™: ${permission}`;
        setVoiceError(`æµ‹è¯•å¤±è´¥: ${errorMsg}`);
      }

    } catch (error) {
      console.error('ðŸ§ª æµ‹è¯•å‡ºé”™:', error);
      setVoiceError('æµ‹è¯•è¿‡ç¨‹å‡ºé”™: ' + error.message);
    }
  }, [startVoiceInput, stopVoiceInput, voiceState.isListening]);

  const speakText = useCallback((text) => {
    if (!voiceEnabled) return;

    try {
      // åœæ­¢ä¹‹å‰çš„æ’­æŠ¥
      window.speechSynthesis.cancel();

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'zh-CN';
      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      
      utterance.onstart = () => console.log('ðŸ”Š å¼€å§‹è¯­éŸ³æ’­æŠ¥');
      utterance.onend = () => console.log('ðŸ”Š è¯­éŸ³æ’­æŠ¥ç»“æŸ');
      utterance.onerror = (e) => console.error('æ’­æŠ¥é”™è¯¯:', e);

      window.speechSynthesis.speak(utterance);
    } catch (error) {
      console.error('è¯­éŸ³æ’­æŠ¥å¤±è´¥:', error);
    }
  }, [voiceEnabled]);

  return {
    voiceState,
    voiceError,
    isPressing,
    startVoiceInput,
    stopVoiceInput,
    clearVoiceError,
    mobileQuickTest,
    speakText
  };
};