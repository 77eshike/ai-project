// src/hooks/useSpeechRecognition.js - ä¿®å¤ç‰ˆæœ¬
import { useState, useEffect, useCallback, useRef } from 'react';

const useSpeechRecognition = (options = {}) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [finalTranscript, setFinalTranscript] = useState('');
  const [error, setError] = useState(null);
  const [permissionState, setPermissionState] = useState('prompt');
  
  const recognitionRef = useRef(null);
  const isSupportedRef = useRef(false);

  // æ£€æŸ¥éº¦å…‹é£Žæƒé™
  const checkMicrophonePermission = useCallback(async () => {
    try {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        return 'unsupported';
      }
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      
      // ç«‹å³åœæ­¢æµï¼Œåªæ£€æŸ¥æƒé™
      stream.getTracks().forEach(track => track.stop());
      return 'granted';
    } catch (error) {
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        return 'denied';
      }
      return 'prompt';
    }
  }, []);

  // è¯·æ±‚éº¦å…‹é£Žæƒé™
  const requestMicrophonePermission = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      
      // ç«‹å³åœæ­¢æµï¼Œåªè¯·æ±‚æƒé™
      stream.getTracks().forEach(track => track.stop());
      setPermissionState('granted');
      return true;
    } catch (error) {
      setPermissionState('denied');
      setError(new Error('éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£Žè®¿é—®'));
      return false;
    }
  }, []);

  // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    isSupportedRef.current = !!SpeechRecognition;
    
    if (isSupportedRef.current) {
      recognitionRef.current = new SpeechRecognition();
      const recognition = recognitionRef.current;
      
      recognition.continuous = false;
      recognition.interimResults = true;
      recognition.lang = 'zh-CN';
      recognition.maxAlternatives = 1;
      
      recognition.onstart = () => {
        console.log('ðŸŽ¤ Web Speech API å¼€å§‹ç›‘å¬');
        setIsListening(true);
        setError(null);
        setPermissionState('granted');
      };
      
      recognition.onresult = (event) => {
        let interim = '';
        let final = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            final += transcript;
          } else {
            interim += transcript;
          }
        }
        
        setTranscript(interim || final);
        if (final) {
          setFinalTranscript(final);
          if (options.onResult) {
            options.onResult(final);
          }
        }
      };
      
      recognition.onerror = (event) => {
        console.error('Web Speech API é”™è¯¯:', event.error);
        
        let errorMessage = 'è¯­éŸ³è¯†åˆ«é”™è¯¯';
        switch (event.error) {
          case 'not-allowed':
          case 'permission-denied':
            errorMessage = 'éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£Žè®¿é—®';
            setPermissionState('denied');
            break;
          case 'no-speech':
            errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥';
            break;
          case 'audio-capture':
            errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£Žè®¾å¤‡';
            break;
          case 'network':
            errorMessage = 'ç½‘ç»œè¿žæŽ¥é—®é¢˜';
            break;
          default:
            errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`;
        }
        
        const error = new Error(errorMessage);
        setError(error);
        setIsListening(false);
        if (options.onError) {
          options.onError(error);
        }
      };
      
      recognition.onend = () => {
        console.log('ðŸŽ¤ Web Speech API ç»“æŸç›‘å¬');
        setIsListening(false);
      };
    } else {
      setError(new Error('æµè§ˆå™¨ä¸æ”¯æŒ Web Speech API'));
    }
  }, [options]);

  // åˆå§‹æƒé™æ£€æŸ¥
  useEffect(() => {
    const initPermission = async () => {
      const permission = await checkMicrophonePermission();
      setPermissionState(permission);
    };
    
    initPermission();
  }, [checkMicrophonePermission]);

  const startListening = useCallback(async () => {
    if (!isSupportedRef.current) {
      const error = new Error('æµè§ˆå™¨ä¸æ”¯æŒ Web Speech API');
      setError(error);
      if (options.onError) {
        options.onError(error);
      }
      return false;
    }
    
    if (isListening) {
      console.log('âš ï¸ å·²ç»åœ¨ç›‘å¬ä¸­');
      return false;
    }
    
    // æ£€æŸ¥æƒé™
    if (permissionState === 'denied') {
      const error = new Error('éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£Žè®¿é—®');
      setError(error);
      if (options.onError) {
        options.onError(error);
      }
      return false;
    }
    
    // å¦‚æžœæƒé™æœªç¡®å®šï¼Œå…ˆè¯·æ±‚æƒé™
    if (permissionState === 'prompt') {
      const granted = await requestMicrophonePermission();
      if (!granted) {
        return false;
      }
    }
    
    try {
      recognitionRef.current.start();
      return true;
    } catch (error) {
      console.error('å¯åŠ¨ Web Speech API å¤±è´¥:', error);
      setError(error);
      if (options.onError) {
        options.onError(error);
      }
      return false;
    }
  }, [isListening, permissionState, options, requestMicrophonePermission]);

  const stopListening = useCallback(() => {
    if (!isSupportedRef.current || !isListening) {
      return false;
    }
    
    try {
      recognitionRef.current.stop();
      return true;
    } catch (error) {
      console.error('åœæ­¢ Web Speech API å¤±è´¥:', error);
      setError(error);
      return false;
    }
  }, [isListening]);

  const clearTranscript = useCallback(() => {
    setTranscript('');
    setFinalTranscript('');
    setError(null);
  }, []);

  const requestPermission = useCallback(async () => {
    return await requestMicrophonePermission();
  }, [requestMicrophonePermission]);

  return {
    isListening,
    transcript,
    finalTranscript,
    error,
    startListening,
    stopListening,
    clearTranscript,
    requestPermission,
    isSupported: isSupportedRef.current,
    permissionState
  };
};

export default useSpeechRecognition;