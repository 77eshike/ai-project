// components/VoiceRecognition.jsï¼ˆç»“æœä¿®å¤ç‰ˆï¼‰
import { useState, useRef, useCallback, useEffect } from 'react';

const VoiceRecognition = ({ onTranscript, onError, autoStop = true }) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [isSupported, setIsSupported] = useState(true);
  const [permissionStatus, setPermissionStatus] = useState('prompt');
  const recognitionRef = useRef(null);
  const timeoutRef = useRef(null);
  const stopTimeoutRef = useRef(null);
  
  // ç”¨äºç´¯ç§¯è¯†åˆ«ç»“æœ
  const finalTranscriptRef = useRef('');
  const interimTranscriptRef = useRef('');

  // æ£€æŸ¥æƒé™çŠ¶æ€
  useEffect(() => {
    if ('permissions' in navigator) {
      navigator.permissions.query({ name: 'microphone' }).then(permissionStatus => {
        setPermissionStatus(permissionStatus.state);
        permissionStatus.onchange = () => {
          setPermissionStatus(permissionStatus.state);
        };
      });
    }
  }, []);

  // å¯é çš„åœæ­¢å‡½æ•°
  const stopListening = useCallback(() => {
    if (!recognitionRef.current || !isListening) return;

    // æ¸…ç†è¶…æ—¶
    if (stopTimeoutRef.current) {
      clearTimeout(stopTimeoutRef.current);
      stopTimeoutRef.current = null;
    }

    try {
      setIsListening(false);
      recognitionRef.current.stop();
      
      // è®¾ç½®è¶…æ—¶ä¿æŠ¤
      stopTimeoutRef.current = setTimeout(() => {
        console.log('è¯­éŸ³è¯†åˆ«åœæ­¢è¶…æ—¶ä¿æŠ¤');
        recognitionRef.current = null;
      }, 2000);
      
    } catch (error) {
      console.error('åœæ­¢è¯­éŸ³è¯†åˆ«é”™è¯¯:', error);
      recognitionRef.current = null;
    }
    
    // ç¡®ä¿æœ€ç»ˆç»“æœè¢«ä¼ é€’
    if (finalTranscriptRef.current && onTranscript) {
      onTranscript(finalTranscriptRef.current.trim());
    }
  }, [isListening, onTranscript]);

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      setIsSupported(false);
      if (onError) onError('Speech recognition not supported in this browser');
      return;
    }

    recognitionRef.current = new SpeechRecognition();
    const recognition = recognitionRef.current;

    recognition.continuous = false;
    recognition.interimResults = true;
    recognition.lang = 'zh-CN';
    recognition.maxAlternatives = 1;

    // ä¿®å¤ç»“æœå¤„ç†é€»è¾‘
    recognition.onresult = (event) => {
      let newFinalTranscript = finalTranscriptRef.current;
      let newInterimTranscript = '';
      
      // ç¡®ä¿æœ‰ç»“æœæ‰å¤„ç†
      if (event.results.length === 0) return;

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcriptText = result[0].transcript.trim();
        
        if (result.isFinal && transcriptText) {
          newFinalTranscript += (newFinalTranscript ? ' ' : '') + transcriptText;
        } else if (transcriptText) {
          newInterimTranscript += (newInterimTranscript ? ' ' : '') + transcriptText;
        }
      }

      // æ›´æ–°å¼•ç”¨
      if (newFinalTranscript !== finalTranscriptRef.current) {
        finalTranscriptRef.current = newFinalTranscript;
      }
      interimTranscriptRef.current = newInterimTranscript;

      // æ›´æ–°æ˜¾ç¤º
      if (finalTranscriptRef.current) {
        setTranscript(finalTranscriptRef.current);
      } else if (interimTranscriptRef.current) {
        setTranscript(interimTranscriptRef.current + ' ã€è¯†åˆ«ä¸­...ã€‘');
      }
    };

    recognition.onstart = () => {
      console.log('è¯­éŸ³è¯†åˆ«å¼€å§‹');
      setIsListening(true);
      // é‡ç½®çŠ¶æ€
      finalTranscriptRef.current = '';
      interimTranscriptRef.current = '';
      setTranscript('');
    };

    recognition.onend = () => {
      console.log('è¯­éŸ³è¯†åˆ«ç»“æŸ');
      setIsListening(false);
      clearTimeout(timeoutRef.current);
      
      // ç¡®ä¿æœ€ç»ˆç»“æœè¢«è®¾ç½®
      if (finalTranscriptRef.current) {
        setTranscript(finalTranscriptRef.current);
        if (onTranscript) {
          onTranscript(finalTranscriptRef.current.trim());
        }
      } else if (interimTranscriptRef.current) {
        setTranscript(interimTranscriptRef.current);
      }
      
      // æ¸…ç†åœæ­¢è¶…æ—¶
      if (stopTimeoutRef.current) {
        clearTimeout(stopTimeoutRef.current);
        stopTimeoutRef.current = null;
      }
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      setIsListening(false);
      clearTimeout(timeoutRef.current);
      
      // æ¸…ç†åœæ­¢è¶…æ—¶
      if (stopTimeoutRef.current) {
        clearTimeout(stopTimeoutRef.current);
        stopTimeoutRef.current = null;
      }
      
      let errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`;
      
      switch (event.error) {
        case 'not-allowed':
        case 'permission-denied':
          errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ã€‚è¯·æ£€æŸ¥æµè§ˆå™¨è®¾ç½®å¹¶å…è®¸éº¦å…‹é£è®¿é—®ã€‚';
          setPermissionStatus('denied');
          break;
        case 'no-speech':
          errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥ã€‚è¯·ç¡®ä¿éº¦å…‹é£æ­£å¸¸å·¥ä½œã€‚';
          break;
        case 'audio-capture':
          errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·æ£€æŸ¥éº¦å…‹é£è¿æ¥ã€‚';
          break;
        case 'network':
          errorMessage = 'ç½‘ç»œé”™è¯¯ï¼Œè¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨ã€‚';
          break;
        default:
          errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`;
      }
      
      if (onError) onError(errorMessage);
    };

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      clearTimeout(timeoutRef.current);
      if (stopTimeoutRef.current) {
        clearTimeout(stopTimeoutRef.current);
      }
    };
  }, [onTranscript, onError, autoStop, stopListening]);

  // å¢å¼ºçš„å¼€å§‹ç›‘å¬å‡½æ•°
  const startListening = useCallback(async () => {
    if (!recognitionRef.current) {
      if (onError) onError('è¯­éŸ³è¯†åˆ«æœªåˆå§‹åŒ–');
      return;
    }

    if (isListening) {
      console.log('è¯­éŸ³è¯†åˆ«å·²åœ¨è¿è¡Œä¸­');
      return;
    }

    if (permissionStatus === 'denied') {
      if (onError) onError('éº¦å…‹é£æƒé™å·²è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­ä¿®æ”¹æƒé™');
      return;
    }

    try {
      // é‡ç½®çŠ¶æ€
      finalTranscriptRef.current = '';
      interimTranscriptRef.current = '';
      setTranscript('');
      
      recognitionRef.current.start();
      console.log('å°è¯•å¯åŠ¨è¯­éŸ³è¯†åˆ«...');

      timeoutRef.current = setTimeout(() => {
        if (!isListening) {
          console.log('è¯­éŸ³è¯†åˆ«å¯åŠ¨è¶…æ—¶');
          if (onError) onError('è¯­éŸ³è¯†åˆ«å¯åŠ¨è¶…æ—¶ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™');
        }
      }, 3000);

    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        if (onError) onError('éº¦å…‹é£è®¿é—®è¢«æ‹’ç»ã€‚è¯·å…è®¸æµè§ˆå™¨ä½¿ç”¨éº¦å…‹é£ã€‚');
        setPermissionStatus('denied');
      } else if (error.name === 'InvalidStateError') {
        console.log('è¯­éŸ³è¯†åˆ«å·²åœ¨è¿è¡Œ');
        setIsListening(true);
      } else {
        if (onError) onError(`å¯åŠ¨å¤±è´¥: ${error.message}`);
      }
    }
  }, [isListening, onError, permissionStatus]);

  // åˆ‡æ¢ç›‘å¬çŠ¶æ€
  const toggleListening = useCallback(() => {
    if (isListening) {
      stopListening();
    } else {
      startListening();
    }
  }, [isListening, startListening, stopListening]);

  // æ¸…é™¤è½¬å½•æ–‡æœ¬
  const clearTranscript = useCallback(() => {
    setTranscript('');
    finalTranscriptRef.current = '';
    interimTranscriptRef.current = '';
  }, []);

  if (!isSupported) {
    return (
      <div className="voice-recognition unsupported">
        <p>æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨Chromeæˆ–Edgeæµè§ˆå™¨ã€‚</p>
      </div>
    );
  }

  return (
    <div className="voice-recognition">
      {permissionStatus === 'denied' && (
        <div className="permission-warning">
          <p>âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»</p>
          <button 
            onClick={() => window.location.reload()} 
            className="retry-button"
          >
            åˆ·æ–°é¡µé¢å¹¶é‡è¯•
          </button>
        </div>
      )}
      
      <div className="voice-controls">
        <button 
          className={`voice-button ${isListening ? 'listening' : ''}`}
          onClick={toggleListening}
          disabled={permissionStatus === 'denied'}
          aria-label={isListening ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
        >
          <span className="voice-icon">
            {isListening ? 'ğŸ›‘' : 'ğŸ¤'}
          </span>
          {isListening ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
        </button>
        
        {transcript && (
          <button 
            className="clear-button"
            onClick={clearTranscript}
            aria-label="æ¸…é™¤æ–‡æœ¬"
          >
            æ¸…é™¤
          </button>
        )}
      </div>
      
      {isListening && (
        <div className="listening-indicator">
          <div className="pulse"></div>
          <span>æ­£åœ¨è†å¬ä¸­...</span>
        </div>
      )}
      
      {transcript && (
        <div className="transcript">
          <h4>è¯†åˆ«ç»“æœ:</h4>
          <p>{transcript}</p>
        </div>
      )}
      
      <div className="debug-info" style={{ fontSize: '12px', color: '#666', marginTop: '10px' }}>
        çŠ¶æ€: {isListening ? 'å½•éŸ³ä¸­' : 'å¾…æœº'} | æƒé™: {permissionStatus} | æ”¯æŒ: {isSupported ? 'æ˜¯' : 'å¦'}
      </div>
    </div>
  );
};

export default VoiceRecognition;