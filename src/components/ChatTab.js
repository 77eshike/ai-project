// components/ChatTab.js (å®Œå…¨é‡å†™ç‰ˆæœ¬)
import { useState, useEffect, useRef, useCallback, useMemo } from 'react';
import { useKnowledge } from '../contexts/KnowledgeContext';

// åŸºç¡€ç»„ä»¶ä¿æŒä¸å˜
const LoadingIndicator = () => (
  <div className="flex justify-center items-center py-4">
    <div className="flex space-x-2">
      <div className="w-3 h-3 bg-blue-600 rounded-full animate-bounce"></div>
      <div className="w-3 h-3 bg-blue-600 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
      <div className="w-3 h-3 bg-blue-600 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
    </div>
    <span className="ml-2 text-gray-600 text-sm">AIæ­£åœ¨æ€è€ƒä¸­...</span>
  </div>
);

const KnowledgeSaveModal = ({ message, onSave, onClose }) => {
  // ... ä¿æŒä¸å˜
};

const MessageItem = ({ message, voiceEnabled, onSpeak, onSaveAsKnowledge }) => {
  // ... ä¿æŒä¸å˜
};

const ConnectionIndicator = ({ status }) => {
  // ... ä¿æŒä¸å˜
};

// ä¿®å¤ï¼šç®€åŒ–çš„è¯­éŸ³è¯†åˆ« Hook
const useVoiceRecognition = () => {
  const [state, setState] = useState({
    isListening: false,
    isSupported: false,
    error: null,
    transcript: '',
    isMobile: false,
    browserInfo: ''
  });

  const recognitionRef = useRef(null);
  const finalTranscriptRef = useRef('');

  // æ£€æŸ¥æ”¯æŒæ€§
  useEffect(() => {
    const checkSupport = () => {
      if (typeof window === 'undefined') return;
      
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const isSupported = !!SpeechRecognition;
      const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      
      let browserInfo = 'æ¡Œé¢ç«¯';
      if (isMobile) {
        const ua = navigator.userAgent.toLowerCase();
        if (/iphone|ipad|ipod/.test(ua)) {
          browserInfo = /safari/.test(ua) && !/chrome/.test(ua) ? 'iOS Safari' : 'iOS å…¶ä»–æµè§ˆå™¨';
        } else if (/android/.test(ua)) {
          browserInfo = /chrome/.test(ua) ? 'Android Chrome' : 'Android å…¶ä»–æµè§ˆå™¨';
        }
      }

      setState(prev => ({
        ...prev,
        isSupported,
        isMobile,
        browserInfo
      }));
    };

    checkSupport();
  }, []);

  // åœæ­¢è¯†åˆ«
  const stop = useCallback(() => {
    if (!recognitionRef.current) return;
    
    try {
      recognitionRef.current.stop();
    } catch (error) {
      console.log('åœæ­¢è¯†åˆ«æ—¶å‡ºé”™:', error);
    } finally {
      setState(prev => ({ ...prev, isListening: false }));
      recognitionRef.current = null;
    }
  }, []);

  // å¼€å§‹è¯†åˆ«
  const start = useCallback(() => {
    // æ¸…ç†ä¹‹å‰çš„å®ä¾‹
    if (recognitionRef.current) {
      stop();
    }

    if (!state.isSupported) {
      setState(prev => ({ ...prev, error: 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«' }));
      return false;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();

    // åŸºæœ¬é…ç½®
    recognition.continuous = false;
    recognition.interimResults = true;
    recognition.lang = 'zh-CN';
    recognition.maxAlternatives = 1;

    // é‡ç½®çŠ¶æ€
    finalTranscriptRef.current = '';
    setState(prev => ({ 
      ...prev, 
      isListening: true, 
      error: null, 
      transcript: '' 
    }));

    // äº‹ä»¶å¤„ç†
    recognition.onstart = () => {
      console.log('âœ… è¯­éŸ³è¯†åˆ«å¼€å§‹');
    };

    recognition.onresult = (event) => {
      let finalTranscript = '';
      let interimTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0].transcript;
        
        if (result.isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      if (finalTranscript) {
        finalTranscriptRef.current = finalTranscript;
        setState(prev => ({ ...prev, transcript: finalTranscript }));
      } else if (interimTranscript) {
        setState(prev => ({ ...prev, transcript: interimTranscript + '...' }));
      }
    };

    recognition.onerror = (event) => {
      console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
      let errorMessage = 'è¯­éŸ³è¯†åˆ«é”™è¯¯';
      
      switch (event.error) {
        case 'not-allowed':
        case 'permission-denied':
          errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨è®¾ç½®';
          break;
        case 'no-speech':
          errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³';
          break;
        default:
          errorMessage = `è¯†åˆ«é”™è¯¯: ${event.error}`;
      }
      
      setState(prev => ({ 
        ...prev, 
        error: errorMessage, 
        isListening: false 
      }));
    };

    recognition.onend = () => {
      console.log('è¯­éŸ³è¯†åˆ«ç»“æŸ');
      setState(prev => ({ ...prev, isListening: false }));
      recognitionRef.current = null;
    };

    // å¯åŠ¨è¯†åˆ«
    try {
      recognition.start();
      recognitionRef.current = recognition;
      return true;
    } catch (error) {
      console.error('å¯åŠ¨å¤±è´¥:', error);
      setState(prev => ({ 
        ...prev, 
        error: 'å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥', 
        isListening: false 
      }));
      return false;
    }
  }, [state.isSupported, stop]);

  // åˆ‡æ¢è¯†åˆ«çŠ¶æ€
  const toggle = useCallback(() => {
    if (state.isListening) {
      stop();
    } else {
      start();
    }
  }, [state.isListening, start, stop]);

  // æ¸…é™¤é”™è¯¯
  const clearError = useCallback(() => {
    setState(prev => ({ ...prev, error: null }));
  }, []);

  // è·å–æœ€ç»ˆè½¬å½•æ–‡æœ¬
  const getFinalTranscript = useCallback(() => {
    return finalTranscriptRef.current;
  }, []);

  return {
    ...state,
    start,
    stop,
    toggle,
    clearError,
    getFinalTranscript
  };
};

export default function ChatTab({ voiceEnabled, toggleVoice }) {
  const { addKnowledge } = useKnowledge();
  
  const [chatMessages, setChatMessages] = useState([
    { 
      type: 'ai', 
      content: 'æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ç®¡ç†é¡¹ç›®ã€è§£ç­”é—®é¢˜æˆ–æä¾›åˆ›æ„å»ºè®®ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ', 
      time: new Date(),
      saved: false,
      id: Date.now()
    }
  ]);
  const [chatInput, setChatInput] = useState('');
  const [isSending, setIsSending] = useState(false);
  const [connectionStatus, setConnectionStatus] = useState('connected');
  const [savingMessage, setSavingMessage] = useState(null);
  
  // ä½¿ç”¨ä¿®å¤åçš„è¯­éŸ³è¯†åˆ« Hook
  const voiceRecognition = useVoiceRecognition();
  
  const messagesEndRef = useRef(null);
  const speechSynthesisRef = useRef(typeof window !== 'undefined' ? window.speechSynthesis : null);

  // æ»šåŠ¨åˆ°åº•éƒ¨
  const scrollToBottom = useCallback(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, []);

  useEffect(() => {
    scrollToBottom();
  }, [chatMessages, scrollToBottom]);

  // è¯­éŸ³æ’­æŠ¥
  const speakText = useCallback((text) => {
    if (!voiceEnabled || !speechSynthesisRef.current) return;
    
    if (voiceRecognition.isMobile) {
      console.log('ç§»åŠ¨ç«¯è¯­éŸ³æ’­æŠ¥å·²ç¦ç”¨');
      return;
    }
    
    speechSynthesisRef.current.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'zh-CN';
    utterance.rate = 0.9;
    
    speechSynthesisRef.current.speak(utterance);
  }, [voiceEnabled, voiceRecognition.isMobile]);

  // ä¿å­˜çŸ¥è¯†ç‚¹
  const handleSaveAsKnowledge = useCallback((message) => {
    setSavingMessage(message);
  }, []);

  const handleKnowledgeSave = useCallback((knowledgeData) => {
    addKnowledge(knowledgeData);
    setChatMessages(prev => prev.map(msg =>
      msg.id === savingMessage.id ? { ...msg, saved: true } : msg
    ));
    setSavingMessage(null);
  }, [addKnowledge, savingMessage]);

  // å‘é€æ¶ˆæ¯
  const handleSendMessage = useCallback(async () => {
    if (!chatInput.trim() || isSending) return;
    
    // å¦‚æœæ­£åœ¨è¯­éŸ³è¯†åˆ«ï¼Œå…ˆåœæ­¢
    if (voiceRecognition.isListening) {
      voiceRecognition.stop();
      await new Promise(resolve => setTimeout(resolve, 200));
    }
    
    const cleanInput = chatInput.replace(/\.\.\.$/, '').trim();
    if (!cleanInput) return;
    
    const userMessage = {
      type: 'user',
      content: cleanInput,
      time: new Date(),
      saved: false,
      id: Date.now()
    };
    
    setChatMessages(prev => [...prev, userMessage]);
    setChatInput('');
    setIsSending(true);
    
    try {
      setTimeout(() => {
        const aiMessage = {
          type: 'ai',
          content: `æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ï¼š"${cleanInput}"ã€‚è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå›å¤ï¼Œå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨AI APIã€‚`,
          time: new Date(),
          saved: false,
          id: Date.now() + 1
        };
        
        setChatMessages(prev => [...prev, aiMessage]);
        setIsSending(false);
        
        if (voiceEnabled && !voiceRecognition.isMobile) {
          speakText(aiMessage.content);
        }
      }, 1000);
      
    } catch (error) {
      console.error('å‘é€æ¶ˆæ¯é”™è¯¯:', error);
      setIsSending(false);
    }
  }, [chatInput, isSending, voiceRecognition.isListening, voiceRecognition.stop, speakText, voiceEnabled, voiceRecognition.isMobile]);

  const handleKeyPress = useCallback((e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  }, [handleSendMessage]);

  const handleClearChat = useCallback(() => {
    setChatMessages([{
      type: 'ai', 
      content: 'èŠå¤©è®°å½•å·²æ¸…ç©ºã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ', 
      time: new Date(),
      saved: false,
      id: Date.now()
    }]);
  }, []);

  // å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœæ›´æ–°åˆ°è¾“å…¥æ¡†
  useEffect(() => {
    if (voiceRecognition.transcript && !voiceRecognition.isListening) {
      const finalText = voiceRecognition.getFinalTranscript();
      if (finalText) {
        setChatInput(finalText);
      }
    }
  }, [voiceRecognition.transcript, voiceRecognition.isListening, voiceRecognition.getFinalTranscript]);

  // ç»„ä»¶å¸è½½æ¸…ç†
  useEffect(() => {
    return () => {
      if (speechSynthesisRef.current) {
        speechSynthesisRef.current.cancel();
      }
      voiceRecognition.stop();
    };
  }, [voiceRecognition]);

  // æ—¶é—´æ ¼å¼åŒ–
  const formatMessageTime = useCallback((time) => {
    if (!time) return new Date().toLocaleTimeString('zh-CN');
    if (time instanceof Date) {
      return time.toLocaleTimeString('zh-CN', { 
        hour: '2-digit', 
        minute: '2-digit'
      });
    }
    return new Date().toLocaleTimeString('zh-CN');
  }, []);

  // æ¶ˆæ¯å…ƒç´ æ¸²æŸ“
  const messageElements = useMemo(() => {
    return chatMessages.map((message) => (
      <MessageItem 
        key={message.id}
        message={{
          ...message,
          time: formatMessageTime(message.time)
        }}
        voiceEnabled={voiceEnabled} 
        onSpeak={speakText}
        onSaveAsKnowledge={handleSaveAsKnowledge}
      />
    ));
  }, [chatMessages, voiceEnabled, speakText, handleSaveAsKnowledge, formatMessageTime]);

  return (
    <div className="bg-white shadow rounded-lg overflow-hidden h-full flex flex-col">
      <div className="px-4 py-5 sm:p-6 flex-1 flex flex-col">
        <div className="flex justify-between items-center mb-4">
          <h3 className="text-lg font-medium text-gray-900">AIåŠ©æ‰‹å¯¹è¯</h3>
          <div className="flex items-center space-x-4">
            <ConnectionIndicator status={connectionStatus} />
            <button
              onClick={handleClearChat}
              className="text-sm text-gray-600 hover:text-gray-800 transition-colors"
              title="æ¸…ç©ºèŠå¤©è®°å½•"
            >
              æ¸…ç©ºè®°å½•
            </button>
            <div className="flex items-center">
              <span className="text-sm text-gray-600 mr-2">è¯­éŸ³æ’­æŠ¥</span>
              <label className="relative inline-flex items-center cursor-pointer">
                <input 
                  type="checkbox" 
                  className="sr-only" 
                  checked={voiceEnabled}
                  onChange={(e) => toggleVoice(e.target.checked)}
                />
                <div className={`w-11 h-6 bg-gray-200 rounded-full transition-colors ${voiceEnabled ? 'bg-blue-600' : ''}`}></div>
                <div className={`absolute left-1 top-1 bg-white w-4 h-4 rounded-full transition-transform ${voiceEnabled ? 'transform translate-x-5' : ''}`}></div>
              </label>
            </div>
          </div>
        </div>
        
        {/* ç§»åŠ¨ç«¯æç¤º */}
        {voiceRecognition.isMobile && (
          <div className="mb-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg">
            <div className="flex items-center text-yellow-700">
              <span className="text-sm">ğŸ“± ç§»åŠ¨ç«¯æ¨¡å¼: {voiceRecognition.browserInfo}</span>
            </div>
            <div className="mt-1 text-xs text-yellow-600">
              ğŸ’¡ æç¤º: é¦–æ¬¡ä½¿ç”¨éœ€è¦å…è®¸éº¦å…‹é£æƒé™
            </div>
          </div>
        )}
        
        <div className="border rounded-lg flex-1 overflow-y-auto p-4 mb-4 bg-gray-50 min-h-[300px]">
          <div className="space-y-4">
            {messageElements}
            {isSending && <LoadingIndicator />}
            <div ref={messagesEndRef} />
          </div>
        </div>
        
        <div className="flex space-x-2">
          <div className="flex-1 relative">
            <input
              type="text"
              value={chatInput}
              onChange={(e) => setChatInput(e.target.value)}
              onKeyPress={handleKeyPress}
              placeholder={voiceRecognition.isMobile ? "è¾“å…¥æ–‡å­—æˆ–ç‚¹å‡»éº¦å…‹é£è¯´è¯" : "è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–éœ€æ±‚ï¼Œæˆ–ä½¿ç”¨è¯­éŸ³è¾“å…¥..."}
              className="w-full px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 pr-12"
              disabled={isSending}
            />
            {voiceRecognition.isSupported && (
              <button
                onClick={(e) => {
                  e.preventDefault();
                  e.stopPropagation();
                  voiceRecognition.toggle();
                }}
                disabled={isSending}
                className={`absolute right-2 top-1/2 transform -translate-y-1/2 p-2 rounded-full transition-all ${
                  voiceRecognition.isListening 
                    ? 'bg-red-100 text-red-600 border-2 border-red-300 animate-pulse' 
                    : 'bg-gray-100 text-gray-600 hover:bg-gray-200'
                }`}
                type="button"
                title={voiceRecognition.isListening ? 'ç‚¹å‡»åœæ­¢è¯­éŸ³è¾“å…¥' : 'ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥'}
              >
                {voiceRecognition.isListening ? 'ğŸ”´' : 'ğŸ¤'}
              </button>
            )}
          </div>
          <button
            onClick={handleSendMessage}
            disabled={isSending || !chatInput.trim()}
            className="px-6 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed transition-colors"
          >
            {isSending ? 'å‘é€ä¸­...' : 'å‘é€'}
          </button>
        </div>

        {/* è¯­éŸ³çŠ¶æ€æŒ‡ç¤º */}
        {voiceRecognition.isListening && (
          <div className="mt-2 p-3 bg-green-50 border border-green-200 rounded-lg">
            <div className="flex items-center text-green-700">
              <div className="flex space-x-1 mr-3">
                <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce"></div>
                <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
              </div>
              <span className="text-sm font-medium">
                {voiceRecognition.isMobile ? "æ­£åœ¨è†å¬...è¯·é è¿‘éº¦å…‹é£æ¸…æ™°è¯´è¯" : "æ­£åœ¨è†å¬...è¯·å¼€å§‹è¯´è¯"}
              </span>
            </div>
          </div>
        )}

        {/* é”™è¯¯æç¤º */}
        {voiceRecognition.error && (
          <div className="mt-2 p-3 bg-red-50 border border-red-200 rounded-lg">
            <div className="flex justify-between items-start">
              <div className="flex-1">
                <div className="text-sm text-red-700 whitespace-pre-wrap">{voiceRecognition.error}</div>
              </div>
              <div className="flex space-x-2 ml-3">
                <button
                  onClick={voiceRecognition.clearError}
                  className="text-xs text-red-600 hover:text-red-800 px-2 py-1"
                >
                  å¿½ç•¥
                </button>
                <button
                  onClick={voiceRecognition.start}
                  className="text-xs bg-red-100 text-red-700 px-2 py-1 rounded hover:bg-red-200"
                >
                  é‡è¯•
                </button>
              </div>
            </div>
          </div>
        )}

        {/* è°ƒè¯•ä¿¡æ¯ */}
        {process.env.NODE_ENV === 'development' && (
          <div className="mt-2 text-xs text-gray-600 bg-gray-100 p-2 rounded">
            <div><strong>è°ƒè¯•ä¿¡æ¯:</strong></div>
            <div>è®¾å¤‡: {voiceRecognition.isMobile ? 'ç§»åŠ¨ç«¯' : 'æ¡Œé¢ç«¯'} | æµè§ˆå™¨: {voiceRecognition.browserInfo}</div>
            <div>æ”¯æŒ: {voiceRecognition.isSupported ? 'æ˜¯' : 'å¦'} | ç›‘å¬ä¸­: {voiceRecognition.isListening ? 'æ˜¯' : 'å¦'}</div>
            <div>è½¬å½•: "{voiceRecognition.transcript || 'ç©º'}"</div>
          </div>
        )}
      </div>

      {/* çŸ¥è¯†ç‚¹ä¿å­˜æ¨¡æ€æ¡† */}
      {savingMessage && (
        <KnowledgeSaveModal
          message={savingMessage}
          onSave={handleKnowledgeSave}
          onClose={() => setSavingMessage(null)}
        />
      )}
    </div>
  );
}